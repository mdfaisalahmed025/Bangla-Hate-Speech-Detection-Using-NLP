# Bangla-Hate-Speech-Detection-Using-NLP

Anyone can express themselves freely on social
media. Still, many fail to obey community standards and breach
the line of self-limitation, causing harm to others and occasionally
leading to cyberbullying. Hate speech spreads hatred toward a
person or a particular group based on various characteristics,
e.g., race, religion, gender, and so on is referred to as bias.
The offensive speech detection system is the frontier where
researchers are battling to provide secure internet using Natural
Language Processing and machine learning approaches. In this
research, we strive to achieve this goal for those who speak the
Bangla language. Our vision is to create a Bangla Hate Speech
Detection System using natural language processing and machine
learning approaches. In this work, we have made our custom
dataset and used some labeled data from the previous openaccess dataset. Both were merged together and implemented in
this project. We have used around 4,978 data for prepossessing
and running the code. The labeled datasets were categorized into
four distinct classes, i.e., geopolitical, personal, religion, genderabusive and non-hates. This work uses traditional classifiers,
deep learning, transfer learning-based classifiers, or a mix of
both types of classifiers to detect hate speech. Deep learning
is a sort of machine learning that uses data to learn. It may
be used to search for patterns in data. Transfer learning is
a machine learning that allows a machine-learning algorithm
to learn from data that another machine learning algorithm
has already learned. Pretrained approaches have significantly
advanced machine learning and natural language processing
disciplines, including hate speech identification. These methods
were used to identify hate speech. However, we also used Google
API to convert text from Bangla to English. After that the emojis
were removed from the data-sets and again that datas were
converted back to Bangla. Finally, we have got the results where
the best accuracy is in GRU and Attention model which is 98%
. However, the lowest accuracy weâ€™ve got in BERT model is 94%
for this research.
